# Islamic Knowledge Base - Processing Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# LLM API Keys
# =============================================================================
ANTHROPIC_API_KEY=your_anthropic_api_key_here
OPENAI_API_KEY=your_openai_api_key_here  # Optional, for validation/fallback

# =============================================================================
# Database Configuration
# =============================================================================
# PostgreSQL
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=islamic_kb
POSTGRES_USER=ikb_user
POSTGRES_PASSWORD=changeme123

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=  # Leave empty if no password

# Neo4j (Phase 2.5)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=changeme123

# =============================================================================
# Processing Configuration
# =============================================================================
# LLM Settings
LLM_PRIMARY_MODEL=claude-3-5-sonnet-20241022
LLM_SECONDARY_MODEL=gpt-4o  # For validation/fallback
LLM_TEMPERATURE=0.1  # Low for consistency
LLM_MAX_TOKENS=4096

# Rate Limiting
RATE_LIMIT_RPM=5000  # Requests per minute
RATE_LIMIT_TPM=400000  # Tokens per minute
PARALLEL_WORKERS=5  # Number of async workers

# Batch Processing
PCAP_BATCH_SIZE=100
HMSTS_BATCH_SIZE=50
CHECKPOINT_INTERVAL=500  # Save checkpoint every N hadiths

# Cost Tracking
COST_BUDGET_USD=10000  # Maximum LLM API spend
COST_ALERT_THRESHOLD=0.8  # Alert at 80% of budget

# =============================================================================
# Data Paths
# =============================================================================
DATA_DIR=/Users/ns/home/library/ctrl/db
HADITH_DIR=${DATA_DIR}/2. hadith
QURAN_DIR=${DATA_DIR}/1. quran
MARKERS_FILE=${DATA_DIR}/Prophetic_era_markers__v1_.csv
METHODOLOGY_DIR=${DATA_DIR}/methodology

PROCESSED_DIR=${DATA_DIR}/processed
CHECKPOINT_DIR=${PROCESSED_DIR}/checkpoints
EXPORT_DIR=${PROCESSED_DIR}/exports

# =============================================================================
# Logging Configuration
# =============================================================================
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=logs/processing.log
LOG_FORMAT=json  # json or text
LOG_ROTATION=100 MB  # Rotate at this size

# =============================================================================
# Validation Settings
# =============================================================================
MIN_QUALITY_SCORE=0.60  # Flag hadiths below this for review
MIN_TEMPORAL_CONFIDENCE=0.50
MIN_VALIDATION_PASS_RATE=0.95

# Validation toggles
ENABLE_TEMPORAL_VALIDATION=true
ENABLE_SEMANTIC_VALIDATION=true
ENABLE_CONSISTENCY_VALIDATION=true
ENABLE_CLASSICAL_VALIDATION=false  # Phase 2.5 - requires commentary DB

# =============================================================================
# Processing Toggles
# =============================================================================
ENABLE_PROMPT_CACHING=true
ENABLE_RESPONSE_CACHING=true
ENABLE_COST_TRACKING=true
ENABLE_PROGRESS_TRACKING=true

# Processing mode
PROCESSING_MODE=production  # development, production
DRY_RUN=false  # If true, simulate without actual LLM calls

# Resume from checkpoint
RESUME_FROM_CHECKPOINT=true
CHECKPOINT_FILE=  # Leave empty to auto-detect latest

# =============================================================================
# Development Settings
# =============================================================================
DEBUG_MODE=false
VERBOSE_LOGGING=false
SAVE_PROMPTS=false  # Save prompts to disk for debugging
SAVE_RESPONSES=false  # Save LLM responses to disk

# Testing
TEST_HADITH_LIMIT=10  # Process only N hadiths in test mode
TEST_MODE=false
